{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPM034A Machine Learning for socio-technical systems \n",
    "## `Assignment 03: Visualising liveability in Rotterdam`\n",
    "\n",
    "**Delft University of Technology**<br>\n",
    "**Q2 2023**<br>\n",
    "**Instructor:** Sander van Cranenburgh <br>\n",
    "**TAs:**  Francisco Garrido-Valenzuela & Lucas Spierenburg <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Instructions`\n",
    "\n",
    "**Assignments aim to:**<br>\n",
    "* Examine your understanding of the key concepts and techniques.\n",
    "* Examine your the applied ML skills.\n",
    "\n",
    "**Assignments:**<br>\n",
    "* Are graded and must be submitted (see the submission instruction below). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Workspace set-up`\n",
    "\n",
    "**Option 1: Local environment**<br>\n",
    "Uncomment the following cell if you are running this notebook on your local environment. This will install all dependencies on your Python version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 2: Google Colab**<br>\n",
    "Uncomment the following cells code lines if you are running this notebook on Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/TPM034A/Q2_2023\n",
    "#!pip install -r Q2_2023/requirements_colab.txt\n",
    "#!mv \"/content/Q2_2023/Assignments/assignment_03/data\" /content/data\n",
    "#!mv \"/content/Q2_2023/Assignments/assignment_03/assets\" /content/assets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Application: liveability in Rotterdam` <br>\n",
    "\n",
    "### **Introduction**\n",
    "\n",
    "**Liveability** is a concept used to describe the quality of life in a certain area of a city. The liveability of an area is determined by a combination of factors, such as the presence of amenities, the quality of the environment, and the safety in the area. Therefore, liveability is a complex concept that is difficult to measure and/or quantify. In the Netherlands, an instrument developed to analyse liveability (of an area) is called the *Leefbaarometer*. The Leefbaarometer, owned by the Ministry of the Interior and Kingdom Relations, provides an estimate of the liveability  at 100x100 grid (for the entire Netherlands). The Leefbaarometer is used to signal areas with low liveability and to monitor the evolution of liveability over time (monitoring). See this [link](https://www.leefbaarometer.nl/home.php) for more information.\n",
    "\n",
    "Currently, the Leefbaarometer does not consider the visual appearance of urban spaces. But, intuitively a relationship between the two exist (as we explored in Lab Session 03). In this assignment, you will utilise Machine Learning (ML) to predict liveability scores (taken from Leefbaarometer) based on street-level images. Just as we did in Lab session 03 when we predicted neighbourhood attractiveness, your task in this assignment is to explore using ML models to predict liveability and investigate its relationship with the visual appearance of the urban spaces (image embeddings).\n",
    "\n",
    "#### **Data**\n",
    "For this assignment you have access to different datasets. All of them will be available in the data folder after the execution of cell below this instructions. The data folder contains four sub-folder: `image_tabular`, `geo`, `liveability`, and `images`. The following list describes the datasets.\n",
    "\n",
    "1. `data/image_tabular/image_metadata.csv`: A csv file with the image metadata (e.g., year, month or location) of Rotterdam images.\n",
    "2. `data/image_tabular/image_embeddings.csv`: A tabular csv file with image embeddings from Rotterdam.\n",
    "3. `data/geo/grid.gpkg`: A geo dataset of spatial units for the Netherlands called grid cells.\n",
    "4. `data/liveability/liveability_scores.csv`: A tabular csv file with liveability scores for each grid cell in the Netherlands.\n",
    "5. `data/images`: A folder with image files from Rotterdam (read below for more details).\n",
    "\n",
    "As indicated, run the code in the cell below to prepare the dataset. The cell will download the datasets and place them in the data folder automatically for this assigment. It may take up to two minutes to download the data.\n",
    "\n",
    "### **Notes**\n",
    "- The Leefbaarometer is computed for different years and with different models (called verions). The following list provide an explanation of the columns in the liveability dataset:\n",
    "    - `grid_id`: Geographical grid id of the liveability score\n",
    "    - `versie`: Version of the Leefbaarometer model used to determine liveability scores\n",
    "    - `jaar`: Year of the liveability score\n",
    "    - `lbm`: liveability score\n",
    "    - (`afw`, `fys`, `onv`, `soc`, `vrz`, `won`): Other indicators. If you want to explore them visit this [link](https://www.leefbaarometer.nl/home.php).\n",
    "- The liveability data comes at grid level (100mx100m squares). In Lab Session 03 you worked with hexagon shaped data. Therefore, in this assigment you have to associate the image data with the grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTANT: You have to be on the TUDelft network (eduroam) or under eduVPN to run this script\n",
    "from assets import data_downloader as dld\n",
    "dld.download_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tasks and grading**\n",
    "\n",
    "Your assignment is divided into 4 subtasks: (1) Data preparation, (2) Data exploration, (3) Model training, and (4) Reflection. In total, 10 points can be earned in this assignment. The weight per subtask is indicated below. \n",
    "\n",
    "1. **Data preparation** [2.0 pnt]<br>\n",
    "    1. Loading datasets. Load the data from geo, image_tabular, and liveability sub-data folders and visualize them with `df.head()`.<br>\n",
    "    1. Preparing liveability dataset. First, filter the liveability data to keep only the `version 3.0` (`versie` column) and `2020` (`jaar` column). Then, add the grid geometry to the resulting dataset based on `grid_id`. To do so, merge it with the grid dataset.<br>\n",
    "    1. Preparing the image dataset. First, merge the image metadata with the image embeddings using `img_id`. Then, convert the resulting DataFrame into a GeoDataFrame (check the function provided in Lab03). Finally, do a left spatial join (`gpd.sjoin(how = 'left')`) with the grid dataset to add the corresponding grid_id and grid geometry to each image row.<br>\n",
    "    1. Preparing the combined liveability-image dataset. First, merge the liveability data (from 1.2) with the image data (from 1.3) based on grid_id. Then, create two datasets based on two different approaches:<br>\n",
    "        - Grid-level liveability scores: `group by` at grid level and compute the mean of the embeddings columns for each group. Use grid_id as the unit of analysis (this means that in the final dataset each row corresponds to one grid cell). Keep only grid cells with image information (embedding columns) and liveability score. <br>\n",
    "        - Image-level liveability scores: Associate each image with one liveability score based on the grid where the image is located. Use image id as the unit of analysis (in the final dataset each row correspond to one image). Keep only: `img_id`, `img_path`, `in_folder`, `grid_id`, embedding columns, image-point geometry and `lbm`. **[0.5 pnt]**<br>\n",
    "\n",
    "1. **Data exploration** [3.0 pnt]<br>\n",
    "    1. Explore the liveability scores. Plot an histogram of the scores at grid level. Also plot in a map this distribution.<br>\n",
    "    1. Explore the liveability with the images using the two dataset created in 1. \n",
    "        1. Visualize the images from the image-level dataset (from 1.4.2) in groups based on its liveability scores. Similarly as in Lab Session 03 use the number of percentiles (`n_percentiles`) and the number of images per percentile (`images_per_row`) to explore different groups of images.<br>\n",
    "        1. Repeat the previous step but using the grid-level dataset (from 1.4.1).<br>\n",
    "    1. Can you visually see to what extent the images contain information about livability? Which dataset (from 1.4.1 and 1.4.2) is more promising? Comment. <br>\n",
    "\n",
    "1. **Model training** [3 pnt]<br>\n",
    "    1. Use linear regression as benchmark to decide wich dataset (from 1.4.1 and 1.4.2) you have to use for predicting liveability based on the image embedding.<br>\n",
    "    1. Do you think the results from linear regression is consistent with the results from the data exploration? Comment.<br>\n",
    "    1. Train different machine learning models to predict liveability based on the embedding features. Report here two best models you found.<br>\n",
    "    1. Train an ensemble model to see if the performance improves when combining your models.<br>\n",
    "\n",
    "1. **Reflexions** [2 pnt]<br>\n",
    "    1.1. How well do images predict liveability? Can they be used to predict liveability? Comment.<br> \n",
    "    1.2. What are the drawbacks of using this source of data? How this approach can be improved to better predict liveability? Comment.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Learning objective`\n",
    "This assignment provides less structure (i.e. concrete descriptions of tasks we expect you to do) than the previous ones. This is deliberate. By this time, you have more experience. The learning objective is that you are able to reasonably independently apply ML in the context of a socio-technical environment. \n",
    "\n",
    "### **Submission**\n",
    "- The deadline for this assignment is **10 December 2023 23:59** \n",
    "- Use **Python 3.10 or above**\n",
    "- You have to submit your work in zip file with the ipynb **(fully executed)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic libraries\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from PIL import Image\n",
    "\n",
    "# ML tools\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, make_scorer\n",
    "# Models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Visualization libraries\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from branca.element import Figure\n",
    "\n",
    "# Other libraries\n",
    "from pathlib import Path\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Show all columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Data preparation**\n",
    "#### 1.1 Loading datasets. Load the data from geo, image_tabular, and liveability sub-data folders and visualize them with `df.head()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Preparing liveability dataset. First, filter the liveability data to keep only the `version 3.0` (`versie` column) and `2020` (`jaar` column). Then, add the grid geometry to the resulting dataset based on `grid_id`. To do so, merge it with the grid dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. Preparing the image dataset. First, merge the image metadata with the image embeddings using `img_id`. Then, convert the resulting DataFrame into a GeoDataFrame (check the function provided in Lab03). Finally, do a left spatial join (`gpd.sjoin(how = 'left')`) with the grid dataset to add the corresponding grid_id and grid geometry to each image row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4. Preparing the combined liveability-image dataset. First, merge the liveability data (from 1.2) with the image data (from 1.3) based on grid_id. Then, create two datasets based on two different approaches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4.1. Grid-level liveability scores: `group by` at grid level and compute the mean of the embeddings columns for each group. Use grid_id as the unit of analysis (this means that in the final dataset each row correspond to one grid cell). Keep only grid cells with image information (embedding columns) and liveability score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4.2. Image-level liveability scores: Associate each image with one liveability score based on the grid where the image is located. Use images as the unit of analysis (in the final dataset each row correspond to one image). Keep only: `img_id`, `img_path`, `in_folder`, `grid_id`, embedding columns, image-point geometry and `lbm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Data exploration** \n",
    "#### 2.1. Explore the liveability scores. Plot an histogram of the scores at grid level. Also plot in a map this distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Explore how liveability relates to images using the two dataset created in 1.4. \n",
    "##### 2.2.1. Visualise the images from the image-level dataset (from 1.4.2) in groups based on its liveability scores. Similarly as in Lab Session 03 use the number of percentiles (`n_percentiles`) and the number of images per percentile (`images_per_row`) to explore different groups of images. Remember to use only images available in the folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.2. Repeat the previous step but using the grid-level dataset (from 1.4.1). To select the images, pick up them randomly from each grid cell. Remember to use only images available in the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. Can you visually see to what extent the images contain information about liveability? Which dataset (from 1.4.1 and 1.4.2) is more promising? Comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Model training**\n",
    "#### 3.1. Use linear regression as benchmark to decide wich dataset (from 1.4.1 and 1.4.2) to use for predicting liveability based on the image embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_regression_perf(model, X_train, X_test, Y_train, Y_test):\n",
    "    \n",
    "    # Make prediction with the trained model\n",
    "    Y_pred_train = model.predict(X_train)\n",
    "    Y_pred_test = model.predict(X_test)\n",
    "\n",
    "    # Create a function that computes the MSE, MAE, and R2\n",
    "    def perfs(Y,Y_pred):\n",
    "        mse = mean_squared_error(Y,Y_pred)\n",
    "        mae = mean_absolute_error(Y,Y_pred)\n",
    "        R2 = r2_score(Y,Y_pred)\n",
    "        return mse,mae,R2\n",
    "\n",
    "    # Apply the perfs function to the train and test data sets\n",
    "    mse_train, mae_train, r2_train = perfs(Y_train,Y_pred_train)\n",
    "    mse_test,  mae_test , r2_test  = perfs(Y_test,Y_pred_test)\n",
    "        \n",
    "    # Print results\n",
    "    print('Performance')\n",
    "    print(f'Mean Squared  Error Train | Test: \\t{mse_train:>7.4f}\\t|  {mse_test:>7.4f}')\n",
    "    print(f'Mean Absolute Error Train | Test: \\t{mae_train:>7.4f}\\t|  {mae_test:>7.4f}')\n",
    "    print(f'R2                  Train | Test: \\t{ r2_train:>7.4f}\\t|  {r2_test:>7.4f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Do you think the results from linear regression is consistent with the results from the data exploration? Could you think of an explanation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3. Train different machine learning models to predict liveability based on the embedding features. Report here two best models you found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3.1 Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.1 Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4. Train an ensemble model to see if combining your models the performance is improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Reflection**\n",
    "#### 4.1. How well do the images predict liveability? Can they be used to predict liveability? Comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. What are the drawbacks of using images to predict liveability? How can this approach can be improved to better predict liveability? Comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 64-bit ('tpm34a')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc97a96f317a709ae2c462a7d0437fc605198aec43f9a7dadb54e6d81820938d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
